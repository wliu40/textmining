{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Spark Version 2.2.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"Naive_Bayes\")\n",
    "sc   = SparkContext(conf=conf)\n",
    "print (\"Running Spark Version %s\" % (sc.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"mini_newsgroups/*\"\n",
    "newsgroupsRawData = sc.wholeTextFiles(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(newsgroupsRawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('rec').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfWithoutSchema = spark.createDataFrame(newsgroupsRawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWithoutSchema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfWithoutSchema = dfWithoutSchema.selectExpr(\"_1 as str_label\", \"_2 as text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "dfWithoutSchema = dfWithoutSchema.withColumn('str_label',split('str_label','/')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"str_label\", outputCol=\"label\")\n",
    "indexed_df = indexer.fit(dfWithoutSchema).transform(dfWithoutSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_df,test_df) = indexed_df.randomSplit([0.8, 0.2], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-----+\n",
      "|  str_label|                text|label|\n",
      "+-----------+--------------------+-----+\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "+-----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(str_label='alt.atheism', text='Newsgroups: alt.atheism\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!bb3.andrew.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!pacific.mps.ohio-state.edu!zaphod.mps.ohio-state.edu!howland.reston.ans.net!bogus.sura.net!darwin.sura.net!jhunix.hcf.jhu.edu!news.cs.jhu.edu!jyusenkyou!arromdee\\nFrom: arromdee@jyusenkyou.cs.jhu.edu (Ken Arromdee)\\nSubject: Re: Alt.Atheism FAQ: Constructing a Logical Argument\\nMessage-ID: <C5uErx.HM@blaze.cs.jhu.edu>\\nSender: news@blaze.cs.jhu.edu (Usenet news system)\\nOrganization: Johns Hopkins University CS Dept.\\nReferences: <19930419105214@mantis.co.uk>\\nDate: Wed, 21 Apr 1993 16:50:20 GMT\\nLines: 27\\n\\nHere\\'s a suggestion for the logical argument FAQ.  I don\\'t think it\\'s covered,\\nthough the fallacy probably has a better name than the one I used:  How about\\nit, mathew?\\n\\nINCONSISTENCY AND COUNTEREXAMPLE\\n\\nThis occurs when one party points out that some source of information takes\\nstand A, which is inconsistent with B.  There are two variations in which B is\\neither a mutually-agreed-on premise or else a stand elsewhere from the same\\nsource.  The second party fallaciously responds by saying \"see, the source\\nreally does say B, it\\'s right here!\"; this reply does not refute the allegation\\nof inconsistency because it does not show that the source _only_ says B.\\n\\nExample of the first type: \"The Koran says unbelievers should be treated in\\nthese ways.  We can both agree these are immoral.\"  \"The Koran clearly says in\\nthis other passage that unbelievers are not to be treated that way.\"\\n\\nExample of the second type: \"There are two Biblical creation stories.\"  \"You\\'re\\nwrong, since the Bible clearly describes the creation as [description].\"\\n--\\n\"On the first day after Christmas my truelove served to me...  Leftover Turkey!\\nOn the second day after Christmas my truelove served to me...  Turkey Casserole\\n    that she made from Leftover Turkey.\\n[days 3-4 deleted] ...  Flaming Turkey Wings! ...\\n   -- Pizza Hut commercial (and M*tlu/A*gic bait)\\n\\nKen Arromdee (arromdee@jyusenkyou.cs.jhu.edu)\\n', label=4.0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "# Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "hashingTF = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"features\")\n",
    "#lr = LogisticRegression(maxIter=10, regParam=0.001)\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "pipeline = Pipeline(stages=[tokenizer,remover, hashingTF, nb])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model = pipeline.fit(indexed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                text|prediction|\n",
      "+--------------------+----------+\n",
      "|Newsgroups: alt.a...|       4.0|\n",
      "|Newsgroups: alt.a...|       4.0|\n",
      "|Newsgroups: alt.a...|       4.0|\n",
      "|Newsgroups: alt.a...|       4.0|\n",
      "|Newsgroups: alt.a...|       4.0|\n",
      "|Path: cantaloupe....|       4.0|\n",
      "|Path: cantaloupe....|       4.0|\n",
      "|Path: cantaloupe....|       4.0|\n",
      "|Path: cantaloupe....|       4.0|\n",
      "|Path: cantaloupe....|       4.0|\n",
      "|Path: cantaloupe....|       4.0|\n",
      "|Xref: cantaloupe....|       4.0|\n",
      "|Xref: cantaloupe....|       4.0|\n",
      "|Xref: cantaloupe....|       4.0|\n",
      "|Xref: cantaloupe....|       4.0|\n",
      "|Newsgroups: comp....|       2.0|\n",
      "|Path: cantaloupe....|       6.0|\n",
      "|Path: cantaloupe....|       2.0|\n",
      "|Path: cantaloupe....|       2.0|\n",
      "|Path: cantaloupe....|       2.0|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"text\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Create an RMSE evaluator using the label and predicted columns\n",
    "reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\n",
    "error = reg_eval.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4029714614743543"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-----+\n",
      "|  str_label|                text|label|\n",
      "+-----------+--------------------+-----+\n",
      "|alt.atheism|Xref: cantaloupe....|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Xref: cantaloupe....|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Xref: cantaloupe....|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "|alt.atheism|Newsgroups: alt.a...|  4.0|\n",
      "|alt.atheism|Path: cantaloupe....|  4.0|\n",
      "+-----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "\n",
    "#labelIndexer = StringIndexer(inputCol=\"str_label\", outputCol=\"indexedLabel\").fit(indexed_df)\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "hashingTF = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"features\")\n",
    "featureIndexer = VectorIndexer(inputCol=hashingTF.getOutputCol(), outputCol=\"features_\", maxCategories=4)\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features_\", maxIter=10)\n",
    "pipeline2 = Pipeline(stages=[tokenizer,remover, hashingTF, featureIndexer, gbt])\n",
    "model2 = pipeline2.fit(indexed_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
