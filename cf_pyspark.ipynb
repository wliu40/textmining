{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('rec').getOrCreate()\n",
    "\n",
    "ratings_df_schema = StructType([StructField('userId', IntegerType()),\n",
    "                                StructField('movieId', IntegerType()),\n",
    "                                StructField('rating', DoubleType())])\n",
    "movies_df_schema = StructType([StructField('ID', IntegerType()),\n",
    "                               StructField('title', StringType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rating_df = spark.read.format('com.databricks.spark.csv')\\\n",
    ".options(inferSchema=False, delimiter = '\\t').schema(ratings_df_schema).load( \"ml-100k/u.data\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|   196|    242|   3.0|\n",
      "|   186|    302|   3.0|\n",
      "|    22|    377|   1.0|\n",
      "|   244|     51|   2.0|\n",
      "|   166|    346|   1.0|\n",
      "|   298|    474|   4.0|\n",
      "|   115|    265|   2.0|\n",
      "|   253|    465|   5.0|\n",
      "|   305|    451|   3.0|\n",
      "|     6|     86|   3.0|\n",
      "|    62|    257|   2.0|\n",
      "|   286|   1014|   5.0|\n",
      "|   200|    222|   5.0|\n",
      "|   210|     40|   3.0|\n",
      "|   224|     29|   3.0|\n",
      "|   303|    785|   3.0|\n",
      "|   122|    387|   5.0|\n",
      "|   194|    274|   2.0|\n",
      "|   291|   1042|   4.0|\n",
      "|   234|   1184|   2.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| ID|               title|\n",
      "+---+--------------------+\n",
      "|  1|    Toy Story (1995)|\n",
      "|  2|    GoldenEye (1995)|\n",
      "|  3|   Four Rooms (1995)|\n",
      "|  4|   Get Shorty (1995)|\n",
      "|  5|      Copycat (1995)|\n",
      "|  6|Shanghai Triad (Y...|\n",
      "|  7|Twelve Monkeys (1...|\n",
      "|  8|         Babe (1995)|\n",
      "|  9|Dead Man Walking ...|\n",
      "| 10|  Richard III (1995)|\n",
      "| 11|Seven (Se7en) (1995)|\n",
      "| 12|Usual Suspects, T...|\n",
      "| 13|Mighty Aphrodite ...|\n",
      "| 14|  Postino, Il (1994)|\n",
      "| 15|Mr. Holland's Opu...|\n",
      "| 16|French Twist (Gaz...|\n",
      "| 17|From Dusk Till Da...|\n",
      "| 18|White Balloon, Th...|\n",
      "| 19|Antonia's Line (1...|\n",
      "| 20|Angels and Insect...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_df = spark.read.format('com.databricks.spark.csv')\\\n",
    ".options(inferSchema=False, delimiter = \"|\").schema(movies_df_schema).load(\"ml-100k/u.item\")\n",
    "\n",
    "movie_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training_df, validation_df, test_df) = rating_df.randomSplit([0.6, 0.2, 0.2], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "als = ALS(maxIter = 10, regParam = 0.01, userCol='userId', itemCol='movieId',ratingCol='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = als.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Create an RMSE evaluator using the label and predicted columns\n",
    "reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 2 the RMSE is 0.956949034787736\n",
      "For rank 3 the RMSE is 0.9902136016869953\n",
      "The best model was trained with rank 2\n"
     ]
    }
   ],
   "source": [
    "ranks = [2, 3]\n",
    "errors = [0, 0]\n",
    "models = [0, 0]\n",
    "count = 0\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "for rank in ranks:\n",
    "\n",
    "  # Build the model    \n",
    "  als.setRank(rank)\n",
    "  model = als.fit(training_df)\n",
    "\n",
    "  # Make predictions on validation dataset  \n",
    "  predict_df = model.transform(validation_df)\n",
    "\n",
    "  predicted_ratings_df = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "\n",
    "  # Run the previously created RMSE evaluator, reg_eval, on the predicted_ratings_df DataFrame\n",
    "  error = reg_eval.evaluate(predicted_ratings_df)\n",
    "  errors[count] = error\n",
    "  models[count] = model\n",
    "  print( 'For rank %s the RMSE is %s' % (rank, error) )\n",
    "\n",
    "  if error < min_error:\n",
    "      min_error = error\n",
    "      best_rank = count\n",
    "  count += 1\n",
    "\n",
    "als.setRank(ranks[best_rank])\n",
    "print( 'The best model was trained with rank %s' % ranks[best_rank] )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For rank 4 the RMSE is 1.0176536637313438\n",
    "For rank 5 the RMSE is 1.04993217603843\n",
    "For rank 6 the RMSE is 1.075890753721413\n",
    "For rank 7 the RMSE is 1.0996544846213758\n",
    "The best model was trained with rank 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
